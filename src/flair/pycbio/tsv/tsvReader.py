# Copyright 2006-2025 Mark Diekhans
"""TSV reading classes"""
import sys
import csv
from flair.pycbio.sys import fileOps
from flair.pycbio.tsv.tsvRow import TsvRow
from flair.pycbio.tsv import TsvError

csv.field_size_limit(sys.maxsize)


# typeMap converter for str types were empty represents None
strOrNoneType = (lambda v: None if (v == "") else v,
                 lambda v: "" if (v is None) else v)

# typeMap converter for int types were empty represents None
intOrNoneType = (lambda v: None if (v == "") else int(v),
                 lambda v: "" if (v is None) else str(v))

floatOrNoneType = (lambda v: None if (v == "") else float(v),
                   lambda v: "" if (v is None) else str(v))


class printf_basic_dialect(csv.Dialect):
    """Describes the usual properties for TSV files generated by printf, etc.  Common
    in bioinformatics.  Quotes can be included in data, etc.
    """
    delimiter = '\t'
    quotechar = None
    doublequote = False
    skipinitialspace = False
    lineterminator = '\n'
    quoting = csv.QUOTE_NONE

def _dehashHeader(row):
    if (len(row) > 0) and row[0].startswith('#'):
        # sometimes there is a space after #
        row[0] = row[0][1:].strip()

class ColumnSpecs:
    """Information about columns that is disconnect from the reader.
    This allows rows to pickled with minimal inforation."""
    __slots = ("columns", "extColumns", "columnMap", "colTypes")

    def __init__(self, columns, extColumns, columnMap, types):
        self.columns = columns
        self.extColumns = extColumns
        self.columnMap = columnMap
        self.types = types

    def _fmtColWithTypes(self, row, iCol):
        col = row[iCol]
        if col is None:
            return ""
        ct = self.types[iCol]
        if type(ct) is tuple:
            return ct[1](col)
        else:
            return str(col)

    def _fmtRowWithTypes(self, row):
        outrow = []
        for iCol in range(len(self.columns)):
            outrow.append(self._fmtColWithTypes(row, iCol))
        return outrow

    def _fmtRowNoTypes(self, row):
        outrow = []
        for iCol in range(len(self.columns)):
            col = row[iCol]
            outrow.append(str(col) if col is not None else '')
        return outrow

    def formatRow(self, row):
        "format row to a list of strings given specified types"
        if self.types is not None:
            return self._fmtRowWithTypes(row)
        else:
            return self._fmtRowNoTypes(row)

def _getColTypes(columns, typeMap, defaultColType):
    "save col types as column indexed list"
    if typeMap is not None:
        return [typeMap.get(col, defaultColType) for col in columns]
    elif defaultColType is not None:
        return len(columns) * [defaultColType]
    else:
        return None

def _setupColumns(columnNames, columnNameMapper):
    # n.b. columns could be passed in from client, must copy
    i = 0
    columns = []
    extColumns = [] if columnNameMapper is not None else columns
    colMap = {}
    for col in columnNames:
        if columnNameMapper is not None:
            extColumns.append(col)
            col = columnNameMapper(col)
        columns.append(col)
        if col in colMap:
            raise TsvError("Duplicate column name: '{}'".format(col))
        colMap[col] = i
        i += 1
    return columns, extColumns, colMap

def _columnsSpecBuild(columnNames, typeMap, defaultColType, columnNameMapper):
    "columns maybe either specified or from the header"
    columns, extColumns, columnMap = _setupColumns(columnNames, columnNameMapper)
    colTypes = _getColTypes(columns, typeMap, defaultColType)
    return ColumnSpecs(columns, extColumns, columnMap, colTypes)


class TsvReader:
    """Class for reading TSV files.  Reads header and builds column name to
    column index map.  After a next, object contains a row and each column
    becomes a field name.  It is also can be indexed by column name or int
    index.  Columns can be automatically type converted by column name.  This
    can also read from a dbapi cursor object (must set allowEmpty to true)

    If the first character of the header is '#', the '#' and following spaces
    are ignored and not part of the first column name.
    """

    def __init__(self, fileName, *, rowClass=None, typeMap=None, defaultColType=None,
                 columns=None, columnNameMapper=None, ignoreExtraCols=False,
                 inFh=None, allowEmpty=False, dialect=csv.excel_tab,
                 encoding=None, errors=None):
        """
        Open TSV file and read header into object. Removes leading '#' from
        UCSC-style headers.

        :param fileName: Path to the TSV file, unless `inFh` is provided.
        :param rowClass: Class or factory to construct a row. Called with the
            TsvReader instance and a list of string column values.
        :param typeMap: Dictionary mapping column names to either a type or a
            (parseFunc, formatFunc) tuple. Unlisted columns are left as strings.
            If `columnNameMapper` is used, the keys should be mapped names.
        :param defaultColType: Type to use for columns not listed in `typeMap`.
        :param columns: List of column names to use if no header is present in
            the file.
        :param columnNameMapper: Function to map raw column names to internal
            names before applying `typeMap`.
        :param ignoreExtraCols: If True, extra columns in rows are ignored.
        :param inFh: An open file-like object to read from instead of `fileName`.
            It will not be closed automatically.
        :param allowEmpty: If True, treat empty input as EOF rather than error.
        :param dialect: A `csv.Dialect` instance or dialect name.
        :param encoding: Optional text encoding (e.g., 'utf-8').
        :param errors: Optional error handling strategy (e.g., 'strict',
            'replace', 'ignore').
        """
        self.fileName = fileName
        self.inFh = None
        self._shouldClose = False
        self._reader = None
        self.rowClass = rowClass
        if rowClass is None:
            self.rowClass = TsvRow
        self.ignoreExtraCols = ignoreExtraCols
        try:
            self._openTsv(fileName, inFh, dialect, encoding, errors)
        except Exception as ex:
            self._closeTsv()
            raise TsvError(f"open of TSV failed {fileName}") from ex

        if columns is None:
            columns = self._readHeader(allowEmpty)
        self.columnSpecs = _columnsSpecBuild(columns, typeMap, defaultColType, columnNameMapper)

    @property
    def columns(self):
        "column names after name mapping"
        return self.columnSpecs.columns

    def _openTsv(self, fileName, inFh, dialect, encoding, errors):
        if inFh is not None:
            self.inFh = inFh
            self._shouldClose = False
        else:
            self.inFh = fileOps.opengz(fileName, encoding=encoding, errors=errors)
            self._shouldClose = True
        self._reader = csv.reader(self.inFh, dialect=dialect)

    def _closeTsv(self):
        "close if we opened the file"
        if self._shouldClose:
            self.close()

    def close(self):
        """force close of the file if open, even if this object didn't open
        it.  Normally, close is handled when end of file is reached"""
        if self.inFh is not None:
            self.inFh.close()
            self.inFh = None

    @property
    def lineNum(self):
        return self._reader.line_num

    def _readHeader(self, allowEmpty):
        try:
            row = next(self._reader)
            _dehashHeader(row)
            return row
        except StopIteration:
            if not allowEmpty:
                raise TsvError("empty TSV file", reader=self)
            return []

    def _parseColumnWithTypeMap(self, row, iCol):
        ct = self.columnSpecs.types[iCol]
        cv = ct[0] if isinstance(ct, tuple) else ct
        try:
            # can be None to have formatter but not parser
            if cv is not None:
                row[iCol] = cv(row[iCol])
        except Exception as ex:
            raise TsvError(f"Error converting TSV column {iCol} ({self.columns[iCol]}) to object, value \"{row[iCol]}\"") from ex

    def _parseColumns(self, row):
        "converts columns in row in-place, if needed"
        for iCol in range(len(self.columnSpecs.columns)):
            self._parseColumnWithTypeMap(row, iCol)

    def _constructRow(self, row):
        if self.ignoreExtraCols:
            if len(row) < len(self.columns):
                raise TsvError(f"row has {len(row)} columns, expected at least {len(self.columns)}", reader=self)
        else:
            if len(row) != len(self.columns):
                raise TsvError(f"row has {len(row)} columns, expected exactly {len(self.columns)}", reader=self)

        try:
            if self.columnSpecs.types is not None:
                self._parseColumns(row)
            return self.rowClass(self, row)
        except Exception as ex:
            raise TsvError("Error converting TSV row to object", self) from ex

    def __iter__(self):
        try:
            for row in self._reader:
                yield self._constructRow(row)
        except Exception as ex:
            raise TsvError("Error reading TSV row", self) from ex
        finally:
            self._closeTsv()

    def formatRow(self, row):
        "format row to a list of strings given specified types"
        return self.columnSpecs.formatRow(row)
